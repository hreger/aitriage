{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ED-AI Triage Model\n",
    "\n",
    "This notebook loads real ED datasets and trains a triage prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Loading ED datasets...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "diagnosis_df = pd.read_csv('../data/diagnosis.csv')\n",
    "edstays_df = pd.read_csv('../data/edstays.csv')\n",
    "medrecon_df = pd.read_csv('../data/medrecon.csv')\n",
    "pyxis_df = pd.read_csv('../data/pyxis.csv')\n",
    "triage_df = pd.read_csv('../data/triage.csv')\n",
    "vitals_df = pd.read_csv('../data/vitalsign.csv')\n",
    "\n",
    "print(\"Datasets loaded successfully!\")\n",
    "print(f\"Diagnosis records: {len(diagnosis_df)}\")\n",
    "print(f\"ED stays: {len(edstays_df)}\")\n",
    "print(f\"Medication records: {len(medrecon_df)}\")\n",
    "print(f\"Pyxis records: {len(pyxis_df)}\")\n",
    "print(f\"Triage records: {len(triage_df)}\")\n",
    "print(f\"Vital signs: {len(vitals_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and feature engineering\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# Convert timestamps\n",
    "triage_df['charttime'] = pd.to_datetime(triage_df['charttime'])\n",
    "vitals_df['charttime'] = pd.to_datetime(vitals_df['charttime'])\n",
    "edstays_df['intime'] = pd.to_datetime(edstays_df['intime'])\n",
    "edstays_df['outtime'] = pd.to_datetime(edstays_df['outtime'])\n",
    "\n",
    "# Merge triage and vitals data\n",
    "merged_df = pd.merge(triage_df, vitals_df, on=['subject_id', 'charttime'], how='left')\n",
    "\n",
    "# Fill missing values\n",
    "numeric_cols = ['temperature_y', 'heart_rate_y', 'respiratory_rate_y', 'oxygen_saturation_y', \n",
    "                'blood_pressure_systolic_y', 'blood_pressure_diastolic_y', 'pain_score_y']\n",
    "merged_df[numeric_cols] = merged_df[numeric_cols].fillna(method='ffill')\n",
    "\n",
    "# Use triage vitals if available, otherwise use vitals table\n",
    "merged_df['temperature'] = merged_df['temperature_x'].fillna(merged_df['temperature_y'])\n",
    "merged_df['heart_rate'] = merged_df['heart_rate_x'].fillna(merged_df['heart_rate_y'])\n",
    "merged_df['respiratory_rate'] = merged_df['respiratory_rate_x'].fillna(merged_df['respiratory_rate_y'])\n",
    "merged_df['oxygen_saturation'] = merged_df['oxygen_saturation_x'].fillna(merged_df['oxygen_saturation_y'])\n",
    "merged_df['blood_pressure_systolic'] = merged_df['blood_pressure_systolic_x'].fillna(merged_df['blood_pressure_systolic_y'])\n",
    "merged_df['blood_pressure_diastolic'] = merged_df['blood_pressure_diastolic_x'].fillna(merged_df['blood_pressure_diastolic_y'])\n",
    "merged_df['pain_score'] = merged_df['pain_score_x'].fillna(merged_df['pain_score_y'])\n",
    "\n",
    "# Drop redundant columns\n",
    "cols_to_drop = [col for col in merged_df.columns if col.endswith('_x') or col.endswith('_y')]\n",
    "merged_df = merged_df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Fill remaining missing values with medians\n",
    "for col in numeric_cols:\n",
    "    if col in merged_df.columns:\n",
    "        merged_df[col] = merged_df[col].fillna(merged_df[col].median())\n",
    "\n",
    "print(f\"Processed dataset shape: {merged_df.shape}\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "print(\"Creating features...\")\n",
    "\n",
    "# Create target variable based on acuity level\n",
    "# Acuity 1 = Critical (needs immediate attention)\n",
    "# Acuity 2 = Urgent \n",
    "# Acuity 3 = Less urgent\n",
    "merged_df['urgent'] = (merged_df['acuity_level'] <= 2).astype(int)\n",
    "\n",
    "# Create additional features\n",
    "merged_df['age'] = np.random.randint(18, 90, len(merged_df))  # Placeholder - would come from patient data\n",
    "merged_df['shock_index'] = merged_df['heart_rate'] / merged_df['blood_pressure_systolic']\n",
    "merged_df['fever'] = (merged_df['temperature'] > 38.0).astype(int)\n",
    "merged_df['hypotension'] = (merged_df['blood_pressure_systolic'] < 90).astype(int)\n",
    "merged_df['tachycardia'] = (merged_df['heart_rate'] > 100).astype(int)\n",
    "merged_df['tachypnea'] = (merged_df['respiratory_rate'] > 20).astype(int)\n",
    "merged_df['hypoxia'] = (merged_df['oxygen_saturation'] < 95).astype(int)\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "merged_df['arrival_mode_encoded'] = le.fit_transform(merged_df['arrival_mode'].fillna('Walk-in'))\n",
    "merged_df['consciousness_encoded'] = le.fit_transform(merged_df['consciousness'].fillna('Alert'))\n",
    "\n",
    "# Select features for model\n",
    "feature_cols = [\n",
    "    'age', 'temperature', 'heart_rate', 'respiratory_rate', 'oxygen_saturation',\n",
    "    'blood_pressure_systolic', 'blood_pressure_diastolic', 'pain_score',\n",
    "    'shock_index', 'fever', 'hypotension', 'tachycardia', 'tachypnea', 'hypoxia',\n",
    "    'arrival_mode_encoded', 'consciousness_encoded'\n",
    "]\n",
    "\n",
    "X = merged_df[feature_cols]\n",
    "y = merged_df['urgent']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts()}\")\n",
    "print(\"Features:\", feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and scale data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "print(\"Training Random Forest model...\")\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"\\nModel Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "print(feature_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and scaler\n",
    "print(\"Saving model and preprocessing objects...\")\n",
    "joblib.dump(model, '../models/triage_model.joblib')\n",
    "joblib.dump(scaler, '../models/scaler.joblib')\n",
    "joblib.dump(feature_cols, '../models/feature_cols.joblib')\n",
    "\n",
    "print(\"Model saved to ../models/triage_model.joblib\")\n",
    "print(\"Scaler saved to ../models/scaler.joblib\")\n",
    "print(\"Feature columns saved to ../models/feature_cols.joblib\")\n",
    "\n",
    "# Test prediction on sample data\n",
    "sample_data = X_test_scaled[:5]\n",
    "predictions = model.predict(sample_data)\n",
    "probabilities = model.predict_proba(sample_data)\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "    print(f\"Sample {i+1}: Predicted={'Urgent' if pred else 'Non-urgent'}, Confidence={max(prob):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
